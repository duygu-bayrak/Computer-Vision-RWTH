{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4d85839d674c54298c1431495cf67d69",
     "grade": false,
     "grade_id": "cell-c91913579e265682",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Sliding-Window Object Detection\n",
    "\n",
    "In this exercise we will implement a simple car detector. To accomplish this, we will first implement a feature descriptor similar to the Histogram of Oriented Gradients (HOG). Then using the features computed for (small) image patches with fixed size, we will train a support vector machine (SVM) classifier, to classify whether the input patch corresponds to a car. \n",
    "\n",
    "In the end, given a test image with arbitary shape, we will run our classifier over the image in a sliding window (patch) fashion. We will generate detections at the places where the classifier is very confident that the patch contains a car.\n",
    "\n",
    "You may refer to the original HOG paper, or the following two tutorials, in case you want to freshen up your knowledge on HOG a little bit:\n",
    "\n",
    "- N. Dalal and B. Triggs: Histograms of oriented gradients for human detection. CVPR 2005. http://lear.inrialpes.fr/people/triggs/pubs/Dalal-cvpr05.pdf\n",
    "- https://www.learnopencv.com/histogram-of-oriented-gradients/\n",
    "- http://mccormickml.com/2013/05/09/hog-person-detector-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "25511457ffa05f9f05b70713cc6d5be9",
     "grade": false,
     "grade_id": "cell-614f2bb0543fa99a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<!-- Run this cell to add heading letters per subtask (like a, b, c) -->\n",
    "<style>\n",
    "body {counter-reset: section;}\n",
    "h2:before {counter-increment: section;\n",
    "           content: counter(section, lower-alpha) \") \";}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a1ac9f6dd92a7682217aeaa4d4eb804f",
     "grade": false,
     "grade_id": "cell-4b28f231db58bcd5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "import sklearn.svm\n",
    "import scipy.ndimage\n",
    "import itertools\n",
    "\n",
    "def plot_multiple(images, titles=None, colormap='viridis', \n",
    "                  max_columns=np.inf, imwidth=4, imheight=4, share_axes=False):\n",
    "    \"\"\"Plot multiple images as subplots on a grid.\"\"\"\n",
    "    if titles is None:\n",
    "        titles = [''] *len(images)\n",
    "    assert len(images) == len(titles)\n",
    "    n_images = len(images)\n",
    "    n_cols = min(max_columns, n_images)\n",
    "    n_rows = int(np.ceil(n_images / n_cols))\n",
    "    fig, axes = plt.subplots(\n",
    "        n_rows, n_cols, figsize=(n_cols * imwidth, n_rows * imheight),\n",
    "        squeeze=False, sharex=share_axes, sharey=share_axes)\n",
    "\n",
    "    axes = axes.flat\n",
    "    # Hide subplots without content\n",
    "    for ax in axes[n_images:]:\n",
    "        ax.axis('off')\n",
    "        \n",
    "    if not isinstance(colormap, (list,tuple)):\n",
    "        colormaps = [colormap]*n_images\n",
    "    else:\n",
    "        colormaps = colormap\n",
    "\n",
    "    for ax, image, title, cmap in zip(axes, images, titles, colormaps):\n",
    "        ax.imshow(image, cmap=cmap)\n",
    "        ax.set_title(title)\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        \n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "588aeba4c2d50cdaf50c1fdecb3cc256",
     "grade": false,
     "grade_id": "cell-acc5b20c2c8dc174",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Dataset\n",
    "\n",
    "To train our classifier, we will use the *UIUC dataset* ([official link](https://cogcomp.seas.upenn.edu/Data/Car/), [mirror](https://github.com/Menuka5/Data-sets-for-opencv-classifier-training/raw/master/Other%20Image%20Datasets%20collected/UIUC%20Image%20Database%20for%20Car%20Detection/CarData.zip)). Download and extract it, then use the `load_dataset` function to pre-load images (modify `dataset_dir` to the path where you extracted the dataset). The function will return three lists, containing images for positive training sample, negative training sample, and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6d5042a061bd9b78896dd7896fb51109",
     "grade": false,
     "grade_id": "cell-dfa163d5a5f10947",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def load_dataset(dataset_dir):\n",
    "    def natural_sort_key(s):\n",
    "        return [float(t) if t.isdigit() else t for t in re.split('([0-9]+)', s)]\n",
    "    \n",
    "    def load_images(*path_parts):\n",
    "        paths = glob.glob(os.path.join(dataset_dir, *path_parts))\n",
    "        return [imageio.imread(p) for p in sorted(paths, key=natural_sort_key)]\n",
    "        \n",
    "    train_images_pos = load_images('TrainImages', 'pos-*.pgm')\n",
    "    train_images_neg = load_images('TrainImages', 'neg-*.pgm')\n",
    "    test_images = load_images('TestImages', 'test-*.pgm')\n",
    "    assert (len(train_images_pos) == 550 and \n",
    "            len(train_images_neg) == 500 and\n",
    "            len(test_images) == 170)\n",
    "    return train_images_pos, train_images_neg, test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CHANGE THIS TO THE DATASET PATH ###\n",
    "dataset_dir = 'CarData'\n",
    "train_images_pos, train_images_neg, test_images = load_dataset(dataset_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6ff6da24ee76122a26fbbb8ba654da28",
     "grade": false,
     "grade_id": "cell-67e72bfbff2c8e86",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## HOG-like Descriptor\n",
    "First we want to implement a simple HOG-like descriptor `hoglike_descriptor()` which takes an image and computes the corresponding HOG-like representation. The function should take in following arguments:\n",
    "\n",
    "- `image`: the grayscale image,\n",
    "- `cell_size`: the size of each HOG-like cell in both dimensions, \n",
    "- `n_bins` the number of bins for the gradient orientation, \n",
    "\n",
    "The output should be a three dimensional array. The first two dimensions are the spatial indices of the HOG cell. The third dimension describes the orientation bins of the HOG descriptor. Each spatial cell has to be independently $L_2$ normalized to 1. Note that the original HOG paper describes a more elaborate two-stage normalization scheme, that is why we call our version here a \"HOG-like\" descriptor.\n",
    "\n",
    "There are two variants described in the HOG paper: \"*The orientation bins are evenly spaced over 0°– 180° (“unsigned” gradient) or 0°–360° (“signed” gradient).*\" In this exercise, we will use the former method, this means that for example an angle of 30° ($\\frac{1}{6}\\pi$) belongs to the same bin as an angle of 210° ($\\frac{7}{6}\\pi$).\n",
    "\n",
    "When the dimensions of the images are not a multiple of the `cell_size`, discard the remaining pixels to the right and to the bottom of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "00bfb02bf4614cb0bbc778f5ecb7c840",
     "grade": true,
     "grade_id": "cell-f36e7e8d51b8ba78",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# POINTS: 4\n",
    "\n",
    "def image_gradients_polar(image):\n",
    "    filter_kernel = np.array([[-1,0,1]], dtype=np.float32)\n",
    "    dx = scipy.ndimage.convolve(image, filter_kernel, mode='reflect')\n",
    "    dy = scipy.ndimage.convolve(image, filter_kernel.T, mode='reflect')\n",
    "    magnitude = np.hypot(dx, dy)\n",
    "    direction = np.arctan2(dy, dx) # between -pi and +pi\n",
    "    return magnitude, direction\n",
    "\n",
    "def hoglike_descriptor(image, cell_size=8, n_bins=16):\n",
    "    image = image.astype(np.float32)/255\n",
    "    grad_mag, grad_dir = image_gradients_polar(np.sqrt(image))\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # Normalization\n",
    "    bin_norm = np.linalg.norm(hog, axis=-1, keepdims=True)\n",
    "    return hog / (bin_norm + 1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1b1a6a4dce78577a9e14448985c7674d",
     "grade": false,
     "grade_id": "cell-b06bd0a2af3c9b20",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "A simple way to visualize HOG features is to plot the 90° rotated gradient vector for each bin, with length propotional to the value of the bin. The function `plot_hog` implements this. The 90° rotation makes the image easier to interpret intuitively, because then the lines will approximate the rough shape of the image content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aa7eaedd359b4d5f481cc3c3dea73c5d",
     "grade": false,
     "grade_id": "cell-13b5245084cd3781",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def draw_line(img, pt1, pt2, color, thickness=1):\n",
    "    pt1 = tuple(np.round(pt1*16).astype(int))\n",
    "    pt2 = tuple(np.round(pt2*16).astype(int))\n",
    "    cv2.line(img, pt1, pt2, color=color, shift=4, \n",
    "             thickness=thickness, lineType=cv2.LINE_AA)\n",
    "\n",
    "def plot_hog_cell(image_roi, hog_cell):\n",
    "    \"\"\"Visualize a single HOG cell.\"\"\"\n",
    "    output_size = image_roi.shape[0]\n",
    "    half_bin_size = np.pi / len(hog_cell) / 2\n",
    "    tangent_angles = np.linspace(0, np.pi, len(hog_cell), endpoint=False) + np.pi/2\n",
    "    center = output_size / 2\n",
    "    \n",
    "    for cell_value, tangent_angle in zip(hog_cell, tangent_angles):\n",
    "        cos_sin = np.array([np.cos(tangent_angle), np.sin(tangent_angle)])\n",
    "        offset = cell_value * output_size * cos_sin *0.5\n",
    "        draw_line(image_roi, center - offset, center + offset, \n",
    "                  color=(249,129,42), thickness=3)\n",
    "\n",
    "def plot_hog(image, hog, cell_size=8):\n",
    "    upsample_factor = 96 / cell_size\n",
    "    result = cv2.resize(image, (0, 0), fx=upsample_factor, fy=upsample_factor,\n",
    "                        interpolation=cv2.INTER_NEAREST)\n",
    "    result = cv2.cvtColor(result, cv2.COLOR_GRAY2RGB)\n",
    "    result = (result.astype(np.float32)*0.6).astype(np.uint8)\n",
    "\n",
    "    for y, x in np.ndindex(*hog.shape[:2]):\n",
    "        yx = np.array([y, x])\n",
    "        y0_out, x0_out = (yx * cell_size * upsample_factor).astype(int)\n",
    "        y1_out, x1_out = ((yx+1) * cell_size * upsample_factor).astype(int)\n",
    "        result_roi = result[y0_out:y1_out, x0_out:x1_out]\n",
    "        plot_hog_cell(result_roi, hog[y, x])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a3595dfed68df8be72b4ff58aa1560a5",
     "grade": false,
     "grade_id": "cell-3287227eaa1b657b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Two simple wave images are here to help understand the visualization\n",
    "waves = [imageio.imread('sine.png'), imageio.imread('circular_sine.jpg')]\n",
    "images = waves + train_images_pos[:6] + train_images_neg[:6]\n",
    "hogs = [hoglike_descriptor(image) for image in images]\n",
    "hog_plots = [plot_hog(image, hog) for image, hog in zip(images, hogs)]\n",
    "titles = ['Wave 1', 'Wave 2'] + ['Positive']*6 + ['Negative']*6\n",
    "plot_multiple(hog_plots, titles, max_columns=2, imheight=2, imwidth=4, share_axes=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6d018b0ead4eca16bda2e8fb7438a643",
     "grade": false,
     "grade_id": "cell-81708c7ed10a3b19",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Can you spot any interesting HOG-cells in the positive and negative examples that could be useful for telling cars apart from non-cars? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5a2947c3de1f1e34d1d4c7b1f6d07136",
     "grade": true,
     "grade_id": "cell-8858beb58dc217b8",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "*POINTS: 0*\n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ff671fe09490cfa74e341a4ca868295a",
     "grade": false,
     "grade_id": "cell-b3a168469fda40eb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Support Vector Machine for Classifying Image Windows\n",
    "\n",
    "We now want to train a classifier in our HOG-like feature space to tell cars and non-cars apart. We use a simple linear SVM for this. \n",
    "\n",
    "Given the HOG representation of an image patch, the classifier should predict if the image patch corresponds to a car. The classifier will then be used to detect objects in new test images using sliding windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f22210f41767b97ff23dd8a2f9e3456d",
     "grade": false,
     "grade_id": "cell-9380cbf36c6e9539",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def train_svm(positive_hog_windows, negative_hog_windows):\n",
    "    svm = sklearn.svm.LinearSVC(C=0.01, loss='hinge')\n",
    "    hog_windows = np.concatenate([positive_hog_windows, negative_hog_windows])\n",
    "    svm_input = hog_windows.reshape([len(hog_windows),-1])\n",
    "    svm_target = np.concatenate((\n",
    "            np.full(len(positive_hog_windows), 1, dtype=np.float32),\n",
    "            np.full(len(negative_hog_windows), 0, dtype=np.float32)))\n",
    "    svm.fit(svm_input, svm_target)\n",
    "    return svm\n",
    "\n",
    "def predict_svm(svm, hog_window):\n",
    "    \"\"\"Return the template response, i.e. the SVM's decision function without the sign.\"\"\"\n",
    "    return svm.decision_function(hog_window.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "15211e380463778ee29320b4200e421f",
     "grade": false,
     "grade_id": "cell-29847154ffdb2aee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "print('Computing features...')\n",
    "positive_hog_windows = [hoglike_descriptor(im) for im in train_images_pos]\n",
    "negative_hog_windows = [hoglike_descriptor(im) for im in train_images_neg]\n",
    "duration = time.time()-start_time     \n",
    "print(f'Done. Took {duration:.2f} s.')\n",
    "\n",
    "start_time = time.time()\n",
    "print('Training SVM...')\n",
    "svm = train_svm(positive_hog_windows, negative_hog_windows)\n",
    "duration = time.time()-start_time\n",
    "print(f'Done. Took {duration:.2f} s.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "afe476d0a195382018a6de1a5d46a453",
     "grade": false,
     "grade_id": "cell-f4ec0a6213fcea46",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We can now visualize the SVM's weights. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b205b0b89efa3cb26e229303860393b8",
     "grade": false,
     "grade_id": "cell-d3f2050d2321a17c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "template = svm.coef_.reshape(positive_hog_windows[0].shape)  # reshape weight vector to shape of HOG-descriptor\n",
    "template_pos = np.maximum(0, template) / template.max()      # we cannot visualize negative numbers, so separate\n",
    "template_neg = np.maximum(0, -template) / -template.min()    # them for independent visualization\n",
    "hog_plots = [\n",
    "    plot_hog(np.zeros_like(train_images_pos[0]), template_pos),\n",
    "    plot_hog(np.zeros_like(train_images_pos[0]), template_neg)\n",
    "]\n",
    "titles = ['positive weights', 'negative weights']\n",
    "plot_multiple(hog_plots, titles=titles, max_columns=2, imheight=2, imwidth=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7f68539f016493320a1dd0c07044a38b",
     "grade": true,
     "grade_id": "cell-1df44cec0aec8bce",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "*POINTS: 0*\n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "670dfd70b694c29584ea6af1a9104bef",
     "grade": false,
     "grade_id": "cell-f06a3a5a35ac2571",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Sliding Window-Based Detection\n",
    "\n",
    "Now implement sliding window classification in the function `get_score_map`. It takes as input the trained classifier object `svm`, the HOG representation of a query image and `window_shape`, the shape of the sliding window (height, width). \n",
    "\n",
    "The function should slide a window over the HOG representation, compute the SVM's score for each window location, and return a score map. Notice that the score map will not have the same shape as the input HOG representation, it will be smaller because the full window needs to fit within the image (This is similar to the border effects from the earlier lectures, when sliding a convolutional kernel without padding lead to a smaller output image than the input).\n",
    "\n",
    "Use `predict_svm(svm, hog_window)` to get the SCM's score for a HOG window. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4ec8fee2629646da89f8f062863aafab",
     "grade": true,
     "grade_id": "cell-0f8e401b83dd713e",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# POINTS: 3\n",
    "\n",
    "def get_score_map(svm, hog, window_shape):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return score_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6b549f3725a6e78ec8ff7fec7e879e27",
     "grade": false,
     "grade_id": "cell-d75adee8f93bca38",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The next step is to convert the score map to actual detections. Implement the function `score_map_to_detections` which returns the indices as well as the values of scores that are higher than certain `threshold`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ccadccb177c81c09c8b4fda3e2a9bd79",
     "grade": true,
     "grade_id": "cell-e08ef16279d111d6",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# POINTS: 2\n",
    "\n",
    "def score_map_to_detections(score_map, threshold):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return xs, ys, scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d4b132c4a7f267027b33416a2fc98416",
     "grade": false,
     "grade_id": "cell-40175d3f581ba473",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Finally, we can test our car detector!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7b36d5584c533f0277e0169cdd09ebec",
     "grade": false,
     "grade_id": "cell-b5cc680557b904c2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def draw_detections(image, xs, ys, scores, window_shape, cell_size=8):\n",
    "    offset_size = 0\n",
    "    \n",
    "    h, w = image.shape[:2]\n",
    "    scale_out = 5\n",
    "    output_image = cv2.resize(\n",
    "        image, (w*scale_out, h*scale_out), interpolation=cv2.INTER_NEAREST)\n",
    "    if output_image.ndim < 3:\n",
    "        output_image = cv2.cvtColor(output_image, cv2.COLOR_GRAY2RGB)\n",
    "    output_image = (output_image.astype(np.float32)*0.6).astype(np.uint8)\n",
    "    \n",
    "    window_size_out = np.array(window_shape[::-1]) * cell_size * scale_out\n",
    "    color = (197,255,0)\n",
    "    \n",
    "    for x, y, score in zip(xs, ys, scores):\n",
    "        im_p0 = (np.array([x,y]) * cell_size + offset_size) * scale_out\n",
    "        im_p1 = im_p0 + window_size_out\n",
    "        cv2.rectangle(output_image, tuple(im_p0), tuple(im_p1),\n",
    "                      color, thickness=3, lineType=cv2.LINE_AA)\n",
    "        cv2.putText(output_image, f'{score:.0%}', tuple(im_p0), \n",
    "                    cv2.FONT_HERSHEY_COMPLEX, 1.5, color,\n",
    "                    thickness=2, lineType=cv2.LINE_AA)\n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e85332a4c5c25ad6e7c86832b68ffdb2",
     "grade": false,
     "grade_id": "cell-9c0ebed448cdaaf9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "images, titles = [], []\n",
    "window_shape = positive_hog_windows[0].shape[:2]\n",
    "\n",
    "for test_image in test_images[25:40]:\n",
    "    hog = hoglike_descriptor(test_image)\n",
    "    score_map = get_score_map(svm, hog, window_shape)\n",
    "    xs, ys, scores = score_map_to_detections(score_map, 0.4)\n",
    "    detection_image = draw_detections(\n",
    "        test_image, xs, ys, scores, window_shape)\n",
    "    \n",
    "    images += [plot_hog(test_image, hog), score_map, detection_image]\n",
    "    titles += ['HOG', 'Score map', 'Detections']\n",
    "\n",
    "plot_multiple(images, titles, max_columns=3, imheight=1.8, imwidth=3.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cc0966bb48b32c0ca7156751e318cd37",
     "grade": false,
     "grade_id": "cell-130dc01e9d35e65a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Non-Maximum Suppression\n",
    "\n",
    "Sliding window based detectors often give multiple responses for the same target. A way to compensate such effect is to use non-maximum-suppression (NMS) on the score map. NMS simply looks at every pixel of the score map and keeps it only if it is the maximum in its 8-neighborhood (set it to the minimum value of the input score map otherwise). Implement `nms` which takes a score map, and returns the non-maximum-suppressed one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0200dfe43fa6bb381622635069e78788",
     "grade": true,
     "grade_id": "cell-c8585690dfff6dfe",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# POINTS: 3\n",
    "\n",
    "def nms(score_map):\n",
    "    min_score = score_map.min()\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc971aaa30fe3c97b614d4718768d28d",
     "grade": false,
     "grade_id": "cell-99948ea9dd4fee86",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "images, titles = [], []\n",
    "for test_image in test_images[25:40]:\n",
    "    hog = hoglike_descriptor(test_image)\n",
    "    score_map = nms(get_score_map(svm, hog, window_shape))\n",
    "    xs, ys, scores = score_map_to_detections(score_map, 0.4)\n",
    "    detection_image = draw_detections(\n",
    "        test_image, xs, ys, scores, window_shape)\n",
    "    \n",
    "    images += [plot_hog(test_image, hog), score_map, detection_image]\n",
    "    titles += ['HOG', 'Score map after NMS', 'Detections after NMS']\n",
    "\n",
    "plot_multiple(images, titles, max_columns=3, imheight=1.8, imwidth=3.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d661e0b5aee202efe0ef39b3f632366f",
     "grade": false,
     "grade_id": "cell-2df8fbd27593e652",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Do you see wrong detections?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0f2950cb3e1969ee554c111fad76a8f8",
     "grade": true,
     "grade_id": "cell-185a889c30e2d94c",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "*POINTS: 0*\n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f1095fd82a2016cea471140e57cb1471",
     "grade": false,
     "grade_id": "cell-9395bdd5b1691ae8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's now evaluate the performance of our detector on the full UIUC test set. The dataset's zip contains a Java-based evaluation program, which we can call from this notebook (lines starting with ! are interpreted as shell commands in Jupyter Notebooks).\n",
    "\n",
    "With a correct implementation the [F-measure](https://en.wikipedia.org/wiki/F-score) should be above 90%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ee5a4892365d09c152c08760e8b389a2",
     "grade": false,
     "grade_id": "cell-129fcb6decde5ccc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(test_images, svm, window_shape, descriptor_func=hoglike_descriptor, \n",
    "             cell_size=8, threshold=0.4):\n",
    "    # Write the detections to a file that is understood by the Java-based \n",
    "    # evaluation program supplied with the dataset.\n",
    "    with open('foundLocations.txt', 'w') as f:\n",
    "        for i, test_image in enumerate(test_images):\n",
    "            hog = descriptor_func(test_image)\n",
    "            score_map = nms(get_score_map(svm, hog, window_shape))\n",
    "            xs, ys, scores = score_map_to_detections(score_map, threshold)\n",
    "\n",
    "            f.write(f'{i}: ')\n",
    "            for x,y in zip(xs, ys):\n",
    "                f.write(f'({y*cell_size}, {x*cell_size}) ')\n",
    "            f.write('\\n')\n",
    "    \n",
    "    # Run the evaluation program on our generated file\n",
    "    !java -classpath $dataset_dir Evaluator $dataset_dir/trueLocations.txt foundLocations.txt        \n",
    "\n",
    "evaluate(test_images, svm, window_shape, hoglike_descriptor, threshold=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "35acedb38a120c38cc23f5c99ae5f2a0",
     "grade": false,
     "grade_id": "cell-ecd06720dd1d4f50",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## [OPTIONAL] Soft Assignment to Multiple Bins and Cells\n",
    "\n",
    "In our `hoglike_descriptor`, we have used a simple assignment scheme of gradient vector to HOG bins. Each pixel voted for a single gradient orientation bin of a single spatial cell.\n",
    "\n",
    "Now imagine if a gradient orientation falls on the end of an orientation bin. A small rotation would make it change to its neighboring bin, thus suddenly altering the HOG feature.\n",
    "\n",
    "Similarly, imagine a pixel near the border between HOG-cells (spatially). A small translation of the object by a few pixels would make this gradient vote in the neighboring cell, again largely changing the features.\n",
    "\n",
    "To make our descriptor more robust to small rotations and translations, let's replace this simple assignment scheme with a smooth voting. This will distribute the gradient magnitude over neighboring bins and cells.\n",
    "\n",
    "In particular, we will use trilinear interpolation weights for weighting votes to neighboring bins. This is analogous to bilinear interpolation, but for three dimensional arrays. Remember that our descriptor is a three-dimensional array, and is indexed by two spatial cell indices and an orientation bin index. (If you don't know what bilinear interpolation is, read the first tutorial provided at the beginning of this exercise.)\n",
    "\n",
    "Implement a `hoglike_descriptor_with_interp` function, which has same functionality and signature with `hoglike_descriptor` implemented earlier, but with simple assignment replaced with soft assignment according to trilinear interpolation weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "33f26e3658dc2c6d7bed80a44205a3e7",
     "grade": true,
     "grade_id": "cell-989cf3b87904bf9d",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# POINTS: 0\n",
    "\n",
    "def hoglike_descriptor_with_interp(image, cell_size=8, n_bins=16):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # Normalization\n",
    "    bin_norm = np.linalg.norm(hog, axis=-1, keepdims=True)\n",
    "    return hog / (bin_norm + 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "55fecc7d37ff2b582446de230c08cd93",
     "grade": false,
     "grade_id": "cell-440e483e6ccf7116",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "print('Computing features...')\n",
    "descriptor_func = hoglike_descriptor_with_interp\n",
    "positive_hog_windows = [descriptor_func(im) for im in train_images_pos]\n",
    "negative_hog_windows = [descriptor_func(im) for im in train_images_neg]\n",
    "duration = time.time()-start_time     \n",
    "print(f'Done. Took {duration:.2f} s.')\n",
    "\n",
    "start_time = time.time()\n",
    "print('Training SVM...')\n",
    "svm2 = train_svm(positive_hog_windows, negative_hog_windows)\n",
    "duration = time.time()-start_time\n",
    "print(f'Done. Took {duration:.2f} s.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "51b704403dd08aa4a913facab7f6ed4f",
     "grade": false,
     "grade_id": "cell-66785833dfab0a8e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "evaluate(test_images, svm2, window_shape, \n",
    "         hoglike_descriptor_with_interp, threshold=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0b96583c1a9d467ff5a9ab842e32851d",
     "grade": false,
     "grade_id": "cell-3f66a9a3fe694c68",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Congratulations, you have now implemented a car detector! To conclude, let's visualize it on different test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0316268c157c3c46fe9ca4651087c327",
     "grade": false,
     "grade_id": "cell-3a1ae7ae84845022",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def to_gray(im):\n",
    "    if im.ndim < 3:\n",
    "        return im\n",
    "    else:\n",
    "        return cv2.cvtColor(im, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "streetview_images = [imageio.imread(f'streetview{i}.jpg') for i in range(1,4)]\n",
    "some_uiuc_test_images = test_images[:33]\n",
    "\n",
    "input_images = streetview_images + some_uiuc_test_images\n",
    "detection_images = []\n",
    "\n",
    "for test_image in input_images:\n",
    "    hog = hoglike_descriptor_with_interp(to_gray(test_image))\n",
    "    score_map = nms(get_score_map(svm2, hog, window_shape))\n",
    "    xs, ys, scores = score_map_to_detections(score_map, 0.8)\n",
    "    detection_image = draw_detections(\n",
    "        test_image, xs, ys, scores, window_shape)\n",
    "    detection_images.append(detection_image)\n",
    "\n",
    "plot_multiple(detection_images[:3], max_columns=1, imheight=2, imwidth=6)\n",
    "plot_multiple(detection_images[3:], max_columns=3, imheight=1.8, imwidth=3.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
