{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f723ddd8a888cee30c2e8ee2d0f18ad9",
     "grade": false,
     "grade_id": "cell-fd159f87a2378533",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Local Feature Matching\n",
    "\n",
    "By the end of this exercise, you will be able to transform images of a flat (planar) object, or images taken from the same point into a common reference frame. This is at the core of applications such as panorama stitching.\n",
    "\n",
    "A quick overview:\n",
    "\n",
    "1. We will start with histogram representations for images (or image regions).\n",
    "2. Then we will detect robust keypoints in images and use simple histogram descriptors to describe the neighborhood of each keypoint.\n",
    "3. After this we will compare descriptors from different images using a distance function and establish matching points.\n",
    "4. Using these matching points we will estimate the homography transformation between two images of a planar object (wall with graffiti) and use this to warp one image to look like the other.\n",
    "\n",
    "**Important**:\n",
    "Follow the instructions below when submitting your attempt.\n",
    "Submissions not following these instructions will not be graded.\n",
    "\n",
    "1. Submit in **teams of 3 or 4 students**, add their names and matriculation numbers below. Only **one team member should upload** the solutions.\n",
    "2. **Use jupyter notebook**. Other notebook-editing software (e.g. jupyter-lab, pycharm) might corrupt the notebook files and could have issues with displaying matplotlib interactively.\n",
    "3. **Do not remove, modify or duplicate** any given cells, except those in which you need to fill in your implementation. You can add new cells in order to present additional texts or plots.\n",
    "4. **Restart the kernel and re-run the whole notebook** once before submission. After this step, the cell id should be incremental from top to bottom, and all plots should be displayed.\n",
    "5. **Submit only the `.ipynb` files**, do not upload archives (zip, rar, tar, etc.), images or datasets.\n",
    "6. **Do not change the filenames** of the `.ipynb` files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Team members (names and matriculation numbers):\n",
    "* \n",
    "* \n",
    "* \n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0eafde77e15badfa0977747d9edbc9b5",
     "grade": false,
     "grade_id": "cell-80d0cee89a1fd583",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "import cv2\n",
    "import math\n",
    "from scipy import ndimage\n",
    "from attrdict import AttrDict\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Many useful functions\n",
    "def plot_multiple(images, titles=None, colormap='gray',\n",
    "                  max_columns=np.inf, imwidth=4, imheight=4, share_axes=False):\n",
    "    \"\"\"Plot multiple images as subplots on a grid.\"\"\"\n",
    "    if titles is None:\n",
    "        titles = [''] *len(images)\n",
    "    assert len(images) == len(titles)\n",
    "    n_images = len(images)\n",
    "    n_cols = min(max_columns, n_images)\n",
    "    n_rows = int(np.ceil(n_images / n_cols))\n",
    "    fig, axes = plt.subplots(\n",
    "        n_rows, n_cols, figsize=(n_cols * imwidth, n_rows * imheight),\n",
    "        squeeze=False, sharex=share_axes, sharey=share_axes)\n",
    "\n",
    "    axes = axes.flat\n",
    "    # Hide subplots without content\n",
    "    for ax in axes[n_images:]:\n",
    "        ax.axis('off')\n",
    "        \n",
    "    if not isinstance(colormap, (list,tuple)):\n",
    "        colormaps = [colormap]*n_images\n",
    "    else:\n",
    "        colormaps = colormap\n",
    "\n",
    "    for ax, image, title, cmap in zip(axes, images, titles, colormaps):\n",
    "        ax.imshow(image, cmap=cmap)\n",
    "        ax.set_title(title)\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        \n",
    "    fig.tight_layout()\n",
    "        \n",
    "def load_image(f_name):\n",
    "    return imageio.imread(f_name, as_gray=True).astype(np.float32)/255\n",
    "\n",
    "def convolve_with_two(image, kernel1, kernel2):\n",
    "    \"\"\"Apply two filters, one after the other.\"\"\"\n",
    "    image = ndimage.convolve(image, kernel1)\n",
    "    image = ndimage.convolve(image, kernel2)   \n",
    "    return image\n",
    "\n",
    "def gauss(x, sigma):\n",
    "    return 1 / np.sqrt(2 * np.pi) / sigma * np.exp(- x**2 / 2 / sigma**2)\n",
    "\n",
    "def gaussdx(x, sigma):\n",
    "    return (-1 / np.sqrt(2 * np.pi) / sigma**3 * x *\n",
    "            np.exp(- x**2 / 2 / sigma**2))\n",
    "\n",
    "def gauss_derivs(image, sigma):\n",
    "    kernel_radius = np.ceil(3.0 * sigma)\n",
    "    x = np.arange(-kernel_radius, kernel_radius + 1)[np.newaxis]\n",
    "    G = gauss(x, sigma)\n",
    "    D = gaussdx(x, sigma)\n",
    "    image_dx = convolve_with_two(image, D, G.T)\n",
    "    image_dy = convolve_with_two(image, G, D.T)\n",
    "    return image_dx, image_dy\n",
    "\n",
    "def gauss_filter(image, sigma):\n",
    "    kernel_radius = np.ceil(3.0 * sigma)\n",
    "    x = np.arange(-kernel_radius, kernel_radius + 1)[np.newaxis]\n",
    "    G = gauss(x, sigma)\n",
    "    return convolve_with_two(image, G, G.T)\n",
    "\n",
    "def gauss_second_derivs(image, sigma):\n",
    "    kernel_radius = np.ceil(3.0 * sigma)\n",
    "    x = np.arange(-kernel_radius, kernel_radius + 1)[np.newaxis]\n",
    "    G = gauss(x, sigma)\n",
    "    D = gaussdx(x, sigma)\n",
    "    \n",
    "    image_dx, image_dy = gauss_derivs(image, sigma)\n",
    "    image_dxx = convolve_with_two(image_dx, D, G.T)\n",
    "    image_dyy = convolve_with_two(image_dy, G, D.T)\n",
    "    image_dxy = convolve_with_two(image_dx, G, D.T)\n",
    "    return image_dxx, image_dxy, image_dyy\n",
    "\n",
    "def map_range(x, start, end):\n",
    "    \"\"\"Maps values `x` that are within the range [start, end) to the range [0, 1)\n",
    "    Values smaller than `start` become 0, values larger than `end` become\n",
    "    slightly smaller than 1.\"\"\"\n",
    "    return np.clip((x-start)/(end-start), 0, 1-1e-10)\n",
    "\n",
    "def draw_keypoints(image, points):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "    radius = image.shape[1]//100+1\n",
    "    for x, y in points:\n",
    "        cv2.circle(image, (int(x), int(y)), radius, (1, 0, 0), thickness=2)        \n",
    "    return image\n",
    "\n",
    "def draw_point_matches(im1, im2, point_matches):\n",
    "    result = np.concatenate([im1, im2], axis=1)\n",
    "    result = (result.astype(float)*0.6).astype(np.uint8)\n",
    "    im1_width = im1.shape[1]\n",
    "    for x1, y1, x2, y2 in point_matches:\n",
    "        cv2.line(result, (x1, y1), (im1_width+x2, y2), \n",
    "                 color=(0,255,255), thickness=2, lineType=cv2.LINE_AA)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5f2db10a594c5eb71e8e38f594f8ac8a",
     "grade": false,
     "grade_id": "cell-43c72a4df139e434",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<!-- This adds heading numbers to each section header -->\n",
    "<style>\n",
    "body {counter-reset: section;}\n",
    "h2:before {counter-increment: section;\n",
    "           content: counter(section, lower-alpha) \") \";}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aaf0c082dd8688819ba06cec2dd71ce1",
     "grade": false,
     "grade_id": "cell-f90e0bb51df68d0c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Histograms in 1D\n",
    "\n",
    "If we have a grayscale image, creating a histogram of the gray values tells us how frequently each gray value appears in the image, at a certain discretization level, which is controlled by the number of bins.\n",
    "\n",
    "Implement `compute_1d_histogram(im, n_bins)`. Given an grayscale image `im` with shape `[height, width]` and the number of bins `n_bins`, return a `histogram` array that contains the number of values falling into each bin. Assume that the values (of the image) are in the range \\[0,1), so the specified number of bins should cover the range from 0 to 1. Normalize the resulting histogram to sum to 1. What is the effect of the different bin counts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8a9a92316d2590b2a738b4434f4e9a5f",
     "grade": true,
     "grade_id": "cell-2377073306e8a1ac",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# POINTS: 3\n",
    "\n",
    "def compute_1d_histogram(im, n_bins):\n",
    "    histogram = np.zeros(n_bins)\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8baf93e14d1a03fd25718e82041e0426",
     "grade": false,
     "grade_id": "cell-03329c01dbb890f0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,4, figsize=(10,2), constrained_layout=True)\n",
    "bin_counts = [2, 25, 256]\n",
    "gray_img = imageio.imread('terrain.png', as_gray=True\n",
    "                         ).astype(np.float32)/256\n",
    "\n",
    "axes[0].set_title('Image')\n",
    "axes[0].imshow(gray_img, cmap='gray')\n",
    "for ax, n_bins in zip(axes[1:], bin_counts):\n",
    "    ax.set_title(f'1D histogram with {n_bins} bins')\n",
    "    bin_size = 1/n_bins\n",
    "    x_axis = np.linspace(0, 1, n_bins, endpoint=False)+bin_size/2\n",
    "    hist = compute_1d_histogram(gray_img, n_bins)\n",
    "    ax.bar(x_axis, hist, bin_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "df99f3b342a03691522ca130e1244f44",
     "grade": false,
     "grade_id": "cell-e38e94725db67abe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Histograms in 3D\n",
    "\n",
    "If the pixel values are more than one-dimensional (e.g. three-dimensional RGB, for red, green and blue color channels), we can build a multi-dimensional histogram. In the R, G, B example this will tell us how frequently each *combination* of R, G, B values occurs. (Note that this contains more information than simply building 3 one-dimensional histograms, each for R, G and B, separately. Why?)\n",
    "\n",
    "Implement a new function `compute_3d_histogram(im, n_bins)`, which takes as input an array of shape `[height, width, 3]` and returns a histogram of shape `[n_bins, n_bins, n_bins]`. Again, assume that the range of values is \\[0,1) and normalize the histogram at the end.\n",
    "\n",
    "Visualize the RGB histograms of the images `sunset.png` and `terrain.png` using the provided code and describe what you see. We cannot use a bar chart in 3D. Instead, in the position of each 3D bin (\"voxel\"), we have a sphere, whose volume is proportional to the histogram's value in that bin. The color of the sphere is simply the RGB color that the bin represents. Which number of bins gives the best impression of the color distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4f70c713c2f214f48f53a7f026d5e274",
     "grade": true,
     "grade_id": "cell-689e5fdcb6459371",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# POINTS: 3\n",
    "\n",
    "def compute_3d_histogram(im, n_bins):\n",
    "    histogram = np.zeros([n_bins, n_bins, n_bins], dtype=np.float32)\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "460a9b5c4d2b525a23ba45d242efb9f6",
     "grade": false,
     "grade_id": "cell-78c4edd62b5476f7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_3d_histogram(ax, data, axis_names='xyz'):\n",
    "    \"\"\"Plot a 3D histogram. We plot a sphere for each bin,\n",
    "    with volume proportional to the bin content.\"\"\"\n",
    "    r,g,b = np.meshgrid(*[np.linspace(0,1, dim) for dim in data.shape], indexing='ij')\n",
    "    colors = np.stack([r,g,b], axis=-1).reshape(-1, 3)\n",
    "    marker_sizes = 300 * data**(1/3)\n",
    "    ax.scatter(r.flat, g.flat, b.flat, s=marker_sizes.flat, c=colors, alpha=0.5)\n",
    "    ax.set_xlabel(axis_names[0])\n",
    "    ax.set_ylabel(axis_names[1])\n",
    "    ax.set_zlabel(axis_names[2])\n",
    "\n",
    "paths = ['sunset.png', 'terrain.png']\n",
    "images = [imageio.imread(p) for p in paths]\n",
    "plot_multiple(images, paths)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 4), subplot_kw={'projection': '3d'})\n",
    "for path, ax in zip(paths, axes):\n",
    "    im = imageio.imread(path).astype(np.float32)/256\n",
    "    hist = compute_3d_histogram(im, n_bins=16) # <--- FIDDLE WITH N_BINS HERE\n",
    "    plot_3d_histogram(ax, hist, 'RGB')   \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "87d7256ea1a95017d524ed26f9d0fe44",
     "grade": false,
     "grade_id": "cell-bdbad5c2b4c9c761",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Histograms in 2D\n",
    "\n",
    "Now modify your code to work in 2D. This can be useful, for example, for a gradient image that stores two values for each pixel: the vertical and horizontal derivative. Again, assume the values are in the range \\[0,1).\n",
    "\n",
    "Since gradients can be negative, we need to pick a relevant range of values an map them linearly to the range of \\[0,1) before applying `compute_2d_histogram`. This is implemented by the function `map_range` provided at the beginning of the notebook.\n",
    "\n",
    "In 2D we can plot the histogram as an image. For better visibility of small values, we plot the logarithm of each bin value. Yellowish colors mean high values. The center is (0,0). Can you explain why each histogram looks the way it does for the test images?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "468fb4e65b7160aeb0ef429c8a0f899a",
     "grade": true,
     "grade_id": "cell-65118197bbba9b47",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# POINTS: 3\n",
    "\n",
    "def compute_2d_histogram(im, n_bins):\n",
    "    histogram = np.zeros([n_bins, n_bins], dtype=np.float32)\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7b3a4fbed40cce49be61f4e4c9eb7076",
     "grade": false,
     "grade_id": "cell-1d8b9ccd9662fab9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_gradient_histogram(rgb_im, n_bins):\n",
    "    # Convert to grayscale\n",
    "    gray_im = cv2.cvtColor(im, cv2.COLOR_RGB2GRAY).astype(float)\n",
    "    # Compute Gaussian derivatives\n",
    "    dx, dy = gauss_derivs(gray_im, sigma=2.0)\n",
    "    # Map the derivatives between -10 and 10 to be between 0 and 1\n",
    "    dx = map_range(dx, start=-10, end=10)\n",
    "    dy = map_range(dy, start=-10, end=10)\n",
    "    # Stack the two derivative images along a new\n",
    "    # axis at the end (-1 means \"last\")\n",
    "    gradients = np.stack([dy, dx], axis=-1)\n",
    "    return dx, dy, compute_2d_histogram(gradients, n_bins=16)\n",
    "\n",
    "paths = ['model/obj4__0.png', 'model/obj42__0.png']\n",
    "images, titles = [], []\n",
    "\n",
    "for path in paths:\n",
    "    im = imageio.imread(path)\n",
    "    dx, dy, hist = compute_gradient_histogram(im, n_bins=16)\n",
    "    images += [im, dx, dy, np.log(hist+1e-3)]\n",
    "    titles += [path, 'dx', 'dy', 'Histogram (log)']\n",
    "    \n",
    "plot_multiple(images, titles, max_columns=4, imwidth=2,\n",
    "              imheight=2, colormap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "68307d8491cf342b53b79edc214e0a23",
     "grade": false,
     "grade_id": "cell-1656bc716e328860",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Similar to the function `compute_gradient_histogram` above, we can build a \"Mag/Lap\" histogram from the gradient magnitudes and the Laplacians at each pixel. Refer back to the first exercise to refresh your knowledge of the Laplacian. Implement this in `compute_maglap_histogram`!\n",
    "\n",
    "Make sure to map the relevant range of the gradient magnitude and Laplacian values to \\[0,1) using `map_range()`. For the magnitude you can assume that the values will mostly lie in the range \\[0, 15) and the Laplacian in the range \\[-5, 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9d8cd312c8ab78654ca30d163f572eb8",
     "grade": true,
     "grade_id": "cell-bc865c7401d375c0",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# POINTS: 3\n",
    "\n",
    "def compute_maglap_histogram(rgb_im, n_bins):\n",
    "    # Convert to grayscale\n",
    "    gray_im = cv2.cvtColor(rgb_im, cv2.COLOR_RGB2GRAY).astype(float)\n",
    "    # Compute Gaussian derivatives\n",
    "    sigma = 2\n",
    "    kernel_radius = np.ceil(3.0 * sigma)\n",
    "    x = np.arange(-kernel_radius, kernel_radius + 1)[np.newaxis]\n",
    "    G = gauss(x, sigma)\n",
    "    D = gaussdx(x, sigma)\n",
    "    dx = convolve_with_two(gray_im, D, G.T)\n",
    "    dy = convolve_with_two(gray_im, G, D.T)\n",
    "    \n",
    "    # Compute second derivatives\n",
    "    dxx = convolve_with_two(dx, D, G.T)\n",
    "    dyy = convolve_with_two(dy, G, D.T)\n",
    "\n",
    "    # Compute gradient magnitude and Laplacian\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    mag_lap = np.stack([mag, lap], axis=-1)\n",
    "    return mag, lap, compute_2d_histogram(mag_lap, n_bins=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ca456a4f83d813ab65255f334216868f",
     "grade": false,
     "grade_id": "cell-3517a9fd850a9698",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "paths = [f'model/obj{i}__0.png' for i in [20, 37, 36, 55]]\n",
    "images, titles = [], []\n",
    "\n",
    "for path in paths:\n",
    "    im = imageio.imread(path)\n",
    "    mag, lap, hist = compute_maglap_histogram(im, n_bins=16)\n",
    "    images += [im, mag, lap, np.log(hist+1e-3)]\n",
    "    titles += [path, 'Gradient magn.', 'Laplacian', 'Histogram (log)']\n",
    "    \n",
    "plot_multiple(images, titles, imwidth=2, imheight=2,\n",
    "              max_columns=4, colormap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "141d70935fba1fc4fdbcd8dcd6437c91",
     "grade": false,
     "grade_id": "cell-abc2186d80e6f48e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Comparing Histograms\n",
    "\n",
    "The above histograms looked different, but to quantify this objectively, we need a **distance measure**. The Euclidean distance is a common one.\n",
    "Implement the function `euclidean_distance`, which takes two histograms $P$ and $Q$ as input and returns their Euclidean distance:\n",
    "\n",
    "$$\n",
    "\\textit{dist}_{\\textit{Euclidean}}(P, Q) = \\sqrt{\\sum_{i=1}^{D}{(P_i - Q_i)^2}}\n",
    "$$\n",
    "\n",
    "Another commonly used distance for histograms is the so-called chi-squared ($\\chi^2$) distance, commonly defined as:\n",
    "\n",
    "$$\n",
    "\\chi^2(P, Q) = \\frac{1}{2} \\sum_{i=1}^{D}\\frac{(P_i - Q_i)^2}{P_i + Q_i + \\epsilon}\n",
    "$$\n",
    "\n",
    "Where we can use a small value $\\epsilon$ is used to avoid division by zero.\n",
    "Implement it as `chi_square_distance`. The inputs `hist1` and `hist2` are histogram vectors containing the bin values. Remember to use numpy array functions (such as `np.sum()`) instead of looping over each element in Python (looping is slow)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b680cbb3a8e08a3793edf8f933c2f99b",
     "grade": true,
     "grade_id": "cell-d015d7a6eba16e66",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# POINTS: 2\n",
    "\n",
    "def euclidean_distance(hist1, hist2):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "def chi_square_distance(hist1, hist2, eps=1e-3):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "96e165403e0fe105cd207e79cb9654ea",
     "grade": false,
     "grade_id": "cell-154ba82874bea725",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now let's take the image `obj1__0.png` as reference and let's compare it to `obj91__0.png` and `obj94__0.png`, using an RGB histogram, both with Euclidean and chi-square distance. Can you interpret the results?\n",
    "\n",
    "You can also try other images from the \"model\" folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "72a65cf65318ec509824ca0b2b929c07",
     "grade": false,
     "grade_id": "cell-448563482a565f52",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "im1 = imageio.imread('model/obj1__0.png')\n",
    "im2 = imageio.imread('model/obj91__0.png')\n",
    "im3 = imageio.imread('model/obj94__0.png')\n",
    "n_bins = 8\n",
    "h1 = compute_3d_histogram(im1/256, n_bins)\n",
    "h2 = compute_3d_histogram(im2/256, n_bins)\n",
    "h3 = compute_3d_histogram(im3/256, n_bins)\n",
    "\n",
    "eucl_dist1 = euclidean_distance(h1, h2)\n",
    "chisq_dist1 = chi_square_distance(h1, h2)\n",
    "eucl_dist2 = euclidean_distance(h1, h3)\n",
    "chisq_dist2 = chi_square_distance(h1, h3)\n",
    "\n",
    "titles = ['Reference image',\n",
    "          f'Eucl: {eucl_dist1:.3f}, ChiSq:  {chisq_dist1:.3f}',\n",
    "          f'Eucl: {eucl_dist2:.3f}, ChiSq:  {chisq_dist2:.3f}']\n",
    "plot_multiple([im1, im2, im3], titles, imheight=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4cda6b90a4d9b4216b3da4643a25da26",
     "grade": false,
     "grade_id": "cell-1e0689a19dc7e477",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Keypoint Detection\n",
    "\n",
    "Now we turn to finding keypoints in images.\n",
    "\n",
    "## Harris Detector\n",
    "\n",
    "The Harris detector searches for points, around which the second-moment matrix $M$ of the gradient vector has two large eigenvalues (This $M$ is denoted by $C$ in the Grauman & Leibe script). This matrix $M$ can be written as:\n",
    "\n",
    "$$\n",
    "M(\\sigma, \\tilde{\\sigma}) = G(\\tilde{\\sigma}) \\star \\left[\\begin{matrix} I_x^2(\\sigma) & I_x(\\sigma) \\cdot I_y(\\sigma) \\cr I_x(\\sigma)\\cdot I_y(\\sigma) & I_y^2(\\sigma) \\end{matrix}\\right]\n",
    "$$\n",
    "\n",
    "Note that the matrix $M$ is computed for each pixel (we omitted the $x, y$ dependency in this formula for clarity). In the above notation the 4 elements of the second-moment matrix are considered as full 2D \"images\" (signals) and each of these 4 \"images\" are convolved with the Gaussian $G(\\tilde{\\sigma})$ independently. We have two sigmas $\\sigma$ and $\\tilde{\\sigma}$ here for two different uses of Gaussian blurring:\n",
    "\n",
    "  * first for computing the derivatives themselves (as derivatives-of-Gaussian) with $\\sigma$, and\n",
    "  * then another Gaussian with $\\tilde{\\sigma}$ that operates on \"images\" containing the *products* of the derivatives (such as $I_x^2(\\sigma)$) in order to collect summary statistics from a window around each point.\n",
    "\n",
    "Instead of explicitly computing the eigenvalues $\\lambda_1$ and $\\lambda_2$ of $M$, the following equivalences are used:\n",
    "\n",
    "$$\n",
    "\\det(M) = \\lambda_1 \\lambda_2 = (G(\\tilde{\\sigma}) \\star I_x^2)\\cdot (G(\\tilde{\\sigma}) \\star I_y^2) - (G(\\tilde{\\sigma}) \\star (I_x\\cdot I_y))^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathrm{trace}(M) = \\lambda_1 + \\lambda_2 = G(\\tilde{\\sigma}) \\star I_x^2 + G(\\tilde{\\sigma}) \\star I_y^2\n",
    "$$\n",
    "\n",
    "The Harris criterion is then:\n",
    "\n",
    "$$\n",
    "\\det(M) - \\alpha \\cdot \\mathrm{trace}^2(M) > t\n",
    "$$\n",
    "\n",
    "In practice, the parameters are usually set as $\\tilde{\\sigma} = 2 \\sigma, \\alpha=0.06$.\n",
    "Read more in Section 3.2.1.2 of the Grauman & Leibe script (grauman-leibe-ch3-local-features.pdf in the Moodle).\n",
    "\n",
    "----\n",
    "\n",
    "Write a function `harris_score(im, opts)` which:\n",
    "  - computes the values of $M$ **for each pixel** of the grayscale image `im`\n",
    "  - calculates the trace and the determinant at each pixel\n",
    "  - combines them to the Harris response and returns the resulting image\n",
    "\n",
    "To handle the large number of configurable parameters in this exercise, we will store them in an `opts` object. Use `opts.sigma1` for $\\sigma$, `opts.sigma2` for $\\tilde{\\sigma}$ and `opts.alpha` for $\\alpha$.\n",
    "\n",
    "Furthermore, implement `nms(scores)` to perform non-maximum suppression of the response image.\n",
    "\n",
    "Then look at `score_map_to_keypoints(scores, opts)`. It takes a score map and returns an array of shape `[number_of_corners, 2]`, with each row being the $(x,y)$ coordinates of a found keypoint. We use `opts.score_threshold` as the threshold for considering a point to be a keypoint. (This is quite similar to how we found detections from score maps in the sliding-window detection exercise.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "318f624d9ce5d25bbd1f3793ffbfef66",
     "grade": true,
     "grade_id": "cell-47380bdc13866b81",
     "locked": false,
     "points": 7,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# POINTS: 7\n",
    "\n",
    "def harris_scores(im, opts):\n",
    "    dx, dy = gauss_derivs(im, opts.sigma1)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a6e856b4315576551e70e4ec98576732",
     "grade": true,
     "grade_id": "cell-ba4d3dbe75b0dedb",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# POINTS: 3\n",
    "\n",
    "def nms(scores):\n",
    "    \"\"\"Non-maximum suppression\"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return scores_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4c2fa738e9dcc570a852dee3fe8abf33",
     "grade": false,
     "grade_id": "cell-008f3c41702c4909",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def score_map_to_keypoints(scores, opts):\n",
    "    corner_ys, corner_xs = (scores > opts.score_threshold).nonzero()\n",
    "    return np.stack([corner_xs, corner_ys], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5cf4f691bb9c937458ff11266078c7c7",
     "grade": false,
     "grade_id": "cell-0dd2ce1b3b103c4b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now check the score maps and keypoints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c311dce082f75a03bfdd96d2291620fc",
     "grade": false,
     "grade_id": "cell-1c8a60da113c08ab",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "opts = AttrDict()\n",
    "opts.sigma1=2\n",
    "opts.sigma2=opts.sigma1*2\n",
    "opts.alpha=0.06\n",
    "opts.score_threshold=1e-8\n",
    "\n",
    "paths = ['checkboard.jpg', 'graf.png', 'gantrycrane.png']\n",
    "images = []\n",
    "titles = []\n",
    "for path in paths:\n",
    "    image = load_image(path)\n",
    "    \n",
    "    score_map = harris_scores(image, opts)\n",
    "    score_map_nms = nms(score_map)\n",
    "    keypoints = score_map_to_keypoints(score_map_nms, opts)\n",
    "    keypoint_image = draw_keypoints(image, keypoints)\n",
    "\n",
    "    images += [score_map, keypoint_image]\n",
    "    titles += ['Harris response scores', 'Harris keypoints']\n",
    "plot_multiple(images, titles, max_columns=2, colormap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cbf1f2fba4b7a363c449c081cb33e7f5",
     "grade": false,
     "grade_id": "cell-9ab1f0157369a0bf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Hessian Detector\n",
    "The Hessian detector operates on the second-derivative matrix $H$ (called the “Hessian” matrix)\n",
    "\n",
    "$$\n",
    "H = \\left[\\begin{matrix}I_{xx}(\\sigma) & I_{xy}(\\sigma) \\cr I_{xy}(\\sigma) & I_{yy}(\\sigma)\\end{matrix}\\right] \\tag{6}\n",
    "$$\n",
    "\n",
    "Note that these are *second* derivatives, while the Harris detector computes *products* of *first* derivatives! The score is computed as follows:\n",
    "\n",
    "$$\n",
    "\\sigma^4 \\det(H) = \\sigma^4 (I_{xx}I_{yy} - I^2_{xy}) > t \\tag{7}\n",
    "$$\n",
    "\n",
    "You can read more in Section 3.2.1.1 of the Grauman & Leibe script (grauman-leibe-ch3-local-features.pdf in the Moodle).\n",
    "\n",
    "-----\n",
    "\n",
    "Write a function `hessian_scores(im, opts)`, which:\n",
    "  - computes the four entries of the $H$ matrix for each pixel of a given image, \n",
    "  - calculates the determinant of $H$ to get the response image\n",
    "\n",
    "Use `opts.sigma1` for computing the Gaussian second derivatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3bb1dbe2b1a8e651f9624dbe35f511c3",
     "grade": true,
     "grade_id": "cell-e1cc43f33d907c8f",
     "locked": false,
     "points": 7,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# POINTS: 7\n",
    "\n",
    "def hessian_scores(im, opts):\n",
    "    height, width = im.shape\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "22d7f878d61cfad19b9a61b6e422d6b7",
     "grade": false,
     "grade_id": "cell-7e3e2d83e6cfe9a5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "opts = AttrDict()\n",
    "opts.sigma1=3\n",
    "opts.score_threshold=5e-4\n",
    "\n",
    "paths = ['checkboard.jpg', 'graf.png', 'gantrycrane.png']\n",
    "images = []\n",
    "titles = []\n",
    "for path in paths:\n",
    "    image = load_image(path)\n",
    "    score_map = hessian_scores(image, opts)\n",
    "    score_map_nms = nms(score_map)\n",
    "    keypoints = score_map_to_keypoints(score_map_nms, opts)\n",
    "    keypoint_image = draw_keypoints(image, keypoints)\n",
    "    images += [score_map, keypoint_image]\n",
    "    titles += ['Hessian scores', 'Hessian keypoints']\n",
    "    \n",
    "plot_multiple(images, titles, max_columns=2, colormap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ea7518292624fca7e68b677339bc900a",
     "grade": false,
     "grade_id": "cell-56a6d1db2fefd9d6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Region Descriptor Matching\n",
    "\n",
    "Now that we can detect robust keypoints, we can try to match them across different images of the same object. For this we need a way to compare the neighborhood of a keypoint found in one image with the neighborhood of a keypoint found in another. If the neighborhoods are similar, then the keypoints may represent the same physical point on the object.\n",
    "\n",
    "To compare two neighborhoods, we compute a **descriptor** vector for the image window around each keypoint and then compare these descriptors using a **distance function**.\n",
    "\n",
    "Inspect the following `compute_rgb_descriptors` function that takes a window around each point in `points` and computes a 3D RGB histogram and returns these as row vectors in a `descriptors` array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cf0e870d9a6fa0c57807908b4796695e",
     "grade": false,
     "grade_id": "cell-49b1634994fee483",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_rgb_descriptors(rgb_im, points, opts):\n",
    "    \"\"\"For each (x,y) point in `points` calculate the 3D RGB histogram \n",
    "    descriptor and stack these into a matrix \n",
    "    of shape [num_points, descriptor_length]\n",
    "    \"\"\"\n",
    "    win_half = opts.descriptor_window_halfsize\n",
    "    descriptors = []\n",
    "    rgb_im_01 = rgb_im.astype(np.float32)/256\n",
    "    height, width = rgb_im.shape[:2]\n",
    "    \n",
    "    for (x, y) in points:\n",
    "        y_start = max(0, y-win_half)\n",
    "        y_end = min(y+win_half+1, height)\n",
    "        x_start = max(0, x-win_half)\n",
    "        x_end = min(x+win_half+1, width)\n",
    "        window = rgb_im_01[y_start:y_end, x_start:x_end]\n",
    "        histogram = compute_3d_histogram(window, opts.n_histogram_bins)\n",
    "        descriptors.append(histogram.reshape(-1))\n",
    "\n",
    "    return np.array(descriptors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c8d170faf83419ce71f3c16a1e5c8c00",
     "grade": false,
     "grade_id": "cell-0034f4dd37dc16f9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now write the function `compute_maglap_descriptors`, which works very similarly to `compute_rgb_descriptors`, but computes two-dimensional gradient-magnitude/Laplacian histograms. (Compute the gradient magnitude and the Laplacian for the full image first. See also the beginning of this exercise.) Pay attention to the scale of the gradient-magnitude values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8c574b4349f0db7a5de1a4ebbff6cfc1",
     "grade": true,
     "grade_id": "cell-ca9403e796827050",
     "locked": false,
     "points": 7,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# POINTS: 7\n",
    "\n",
    "def compute_maglap_descriptors(rgb_im, points, opts):\n",
    "    \"\"\"For each (x,y) point in `points` calculate the magnitude-Laplacian\n",
    "    2D histogram descriptor and stack these into a matrix of\n",
    "    shape [num_points, descriptor_length]\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compute the gradient magnitude and Laplacian for each pixel first\n",
    "    gray_im = cv2.cvtColor(rgb_im, cv2.COLOR_RGB2GRAY).astype(float)\n",
    "    kernel_radius = np.ceil(3.0 * opts.sigma1)\n",
    "    x = np.arange(-kernel_radius, kernel_radius + 1)[np.newaxis]\n",
    "    G = gauss(x, opts.sigma1)\n",
    "    D = gaussdx(x, opts.sigma1)\n",
    "    dx = convolve_with_two(gray_im, D, G.T)\n",
    "    dy = convolve_with_two(gray_im, G, D.T)\n",
    "    dxx = convolve_with_two(dx, D, G.T)\n",
    "    dyy = convolve_with_two(dy, G, D.T)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return np.array(descriptors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "89a71ead1a98692dc6b355d3e8872f2d",
     "grade": false,
     "grade_id": "cell-d741767e1fd97cd8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now let's implement the distance computation between descriptors. Look at `compute_euclidean_distances`. It takes descriptors that were computed for keypoints found in two different images and returns the pairwise distances between all point pairs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "48d3c40f439838ea9570c6dafda9c4f4",
     "grade": false,
     "grade_id": "cell-bdeaabc9f8e7227e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_euclidean_distances(descriptors1, descriptors2):\n",
    "    distances = np.empty((len(descriptors1), len(descriptors2)))\n",
    "    for i, desc1 in enumerate(descriptors1):\n",
    "        distances[i] = np.linalg.norm(descriptors2-desc1, axis=-1)\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f488862a4a5951e78ad3c0dabfef53b4",
     "grade": false,
     "grade_id": "cell-e8301748b0ce7339",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Implement `compute_chi_square_distances` in a similar manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "644392e83fe92c30cafb872a5127d394",
     "grade": true,
     "grade_id": "cell-ab4339e397d6b6f8",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# POINTS: 3\n",
    "\n",
    "def compute_chi_square_distances(descriptors1, descriptors2):\n",
    "    distances = np.empty((len(descriptors1), len(descriptors2)))\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7b20336ef127fa0cb3a486f9f8f7b162",
     "grade": false,
     "grade_id": "cell-29ffe545504668da",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Given the distances, a simple way to produce point matches is to take each descriptor extracted from a keypoint of the first image, and find the keypoint in the second image with the nearest descriptor. The full pipeline from images to point matches is implemented below in the function `find_point_matches(im1, im2, opts)`.\n",
    "\n",
    "Experiment with different parameter settings. Which keypoint detector, region descriptor and distance function works best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d5b54ccc58d59a8e538fda7e1097f491",
     "grade": false,
     "grade_id": "cell-b9e301b418b4ee90",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def find_point_matches(im1, im2, opts):\n",
    "    # Process first image\n",
    "    im1_gray = cv2.cvtColor(im1, cv2.COLOR_RGB2GRAY).astype(float)/255\n",
    "    score_map1 = nms(opts.score_func(im1_gray, opts))\n",
    "    points1 = score_map_to_keypoints(score_map1, opts)\n",
    "    descriptors1 = opts.descriptor_func(im1, points1, opts)\n",
    "\n",
    "    # Process second image independently of first\n",
    "    im2_gray = cv2.cvtColor(im2, cv2.COLOR_RGB2GRAY).astype(float)/255\n",
    "    score_map2 = nms(opts.score_func(im2_gray, opts))\n",
    "    points2 = score_map_to_keypoints(score_map2, opts)\n",
    "    descriptors2 = opts.descriptor_func(im2, points2, opts)\n",
    "    \n",
    "    # Compute descriptor distances\n",
    "    distances = opts.distance_func(descriptors1, descriptors2)\n",
    "    \n",
    "    # Find the nearest neighbor of each descriptor from the first image\n",
    "    # among descriptors of the second image\n",
    "    closest_ids = np.argmin(distances, axis=1)\n",
    "    closest_dists = np.min(distances, axis=1)\n",
    "    \n",
    "    # Sort the point pairs in increasing order of distance\n",
    "    # (most similar ones first)\n",
    "    ids1 = np.argsort(closest_dists)\n",
    "    ids2 = closest_ids[ids1]\n",
    "    points1 = points1[ids1]\n",
    "    points2 = points2[ids2]\n",
    "    \n",
    "    # Stack the point matches into rows of (x1, y1, x2, y2) values\n",
    "    point_matches = np.concatenate([points1, points2], axis=1)\n",
    "    return point_matches\n",
    "\n",
    "# Try changing these values in different ways and see if you can explain\n",
    "# why the result changes the way it does.\n",
    "opts = AttrDict()\n",
    "opts.sigma1=2\n",
    "opts.sigma2=opts.sigma1*2\n",
    "opts.alpha=0.06\n",
    "opts.score_threshold=1e-8\n",
    "opts.descriptor_window_halfsize = 20\n",
    "opts.n_histogram_bins = 16\n",
    "opts.score_func = harris_scores\n",
    "opts.descriptor_func = compute_maglap_descriptors\n",
    "opts.distance_func = compute_chi_square_distances\n",
    "\n",
    "# Or try these:\n",
    "#opts.sigma1=3\n",
    "#opts.n_histogram_bins = 8\n",
    "#opts.score_threshold=5e-4\n",
    "#opts.score_func = hessian_scores\n",
    "#opts.descriptor_func = compute_rgb_descriptors\n",
    "#opts.distance_func = compute_euclidean_distances\n",
    "\n",
    "im1 = imageio.imread('graff5/img1.jpg')\n",
    "im2 = imageio.imread('graff5/img2.jpg')\n",
    "\n",
    "point_matches = find_point_matches(im1, im2, opts)\n",
    "match_image = draw_point_matches(im1, im2, point_matches[:50])\n",
    "plot_multiple([match_image], imwidth=16, imheight=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ce02c2ba7709fee1aff2bc01ca8d83d4",
     "grade": false,
     "grade_id": "cell-c79e4e37eb2c3cec",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Homography Estimation\n",
    "\n",
    "Now that we have these pairs of matching points (also called point correspondences), what can we do with them? In the above case, the wall is planar (flat) and the camera was moved towards the left to take the second image compared to the first image. Therefore, the way that points on the wall are transformed across these two images can be modeled as a **homography**. Homographies can model two distinct effects:\n",
    "\n",
    "  * transformation across images of **any scene** taken from the **exact same camera position** (center of projection)\n",
    "  * transformation across images of a **planar object** taken from **any camera position**.\n",
    "  \n",
    "We are dealing with the second case in these graffiti images. Therefore if our point matches are correct, there should be a homography that transforms image points in the first image to the corresponding points in the second image. Recap the algorithm from the lecture for finding this homography (it's called the **Direct Linear Transformation**, DLT). There is a 2 page description of it in the Grauman & Leibe script (grauman-leibe-ch5-geometric-verification.pdf in the Moodle) in Section 5.1.3.\n",
    "\n",
    "----\n",
    "\n",
    "Now let's actually put this into practice. Implement `estimate_homography(point_matches)`, which returns a 3x3 homography matrix that transforms points of the first image to points of the second image.\n",
    "The steps are:\n",
    "\n",
    "  1. Build the matrix $A$ from the point matches according to Eq. 5.7 from the script.\n",
    "  2. Apply SVD using `np.linalg.svd(A)`. It returns $U,d,V^T$. Note that the last return value is not $V$ but $V^T$.\n",
    "  3. Compute $\\mathbf{h}$ from $V$ according to Eq. 5.9 or 5.10\n",
    "  4. Reshape $\\mathbf{h}$ to the 3x3 matrix $H$ and return it.\n",
    "  \n",
    "The input `point_matches` contains as many rows as there are point matches (correspondences) and each row has 4 elements: $x, y, x', y'$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "98cbe715beb51d23ed21c9feb43593b5",
     "grade": true,
     "grade_id": "cell-25d867ba8f5df81c",
     "locked": false,
     "points": 7,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# POINTS: 7\n",
    "\n",
    "def estimate_homography(point_matches):\n",
    "    n_matches = len(point_matches)\n",
    "    A = np.empty((n_matches*2, 9))\n",
    "    for i, (x1, y1, x2, y2) in enumerate(point_matches):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eeae9a1e23c5d7744d643959572b96e1",
     "grade": false,
     "grade_id": "cell-5d385bc9288bd069",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The `point_matches` have already been sorted in the `find_point_matches` function according to the descriptor distances, so the more accurate pairs will be near the beginning. We can use the top $k$, e.g. $k=10$ pairs in the homography estimation and have a reasonably accurate estimate. What $k$ give the best result? What happens if you use too many? Why?\n",
    "\n",
    "We can use `cv2.warpPerspective` to warp the first image to the reference frame of the second. Does the result look good?\n",
    "\n",
    "Can you interpret the entries of the resulting $H$ matrix and are the numbers as you would expect them for these images?\n",
    "\n",
    "You can also try other image from the `graff5` folder or the `NewYork` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8b15c19f1bd7a35f3559cbc8c73f6584",
     "grade": false,
     "grade_id": "cell-51c93ee2e8a910da",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# See what happens if you change top_k below\n",
    "top_k = 50\n",
    "H = estimate_homography(point_matches[:top_k])\n",
    "\n",
    "H_string = np.array_str(H, precision=5, suppress_small=True)\n",
    "print('The estimated homography matrix H is\\n', H_string)\n",
    "\n",
    "im1_warped = cv2.warpPerspective(im1, H, (im2.shape[1], im2.shape[0]))\n",
    "absdiff = np.abs(im2.astype(np.float32)-im1_warped.astype(np.float32))/255\n",
    "plot_multiple([im1, im2, im1_warped, absdiff],\n",
    "              ['First image', 'Second image', \n",
    "               'Warped first image', 'Absolute difference'],\n",
    "              max_columns=2, colormap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
